# asyncio

## 1. Introduction to coroutine

Coroutines are computer program components that generalize subroutines for non-preemptive multitasking, 
by allowing execution to be suspended and resumed.This means that unlike Threads which can be preempted 
from OS, coroutines are not prempted from outside but give up control themselves. This avoids any requirment 
of synchronisation primitives such as lock or critical section.

## 2. The big picture

<div><img src="../../../../../images/diagram.png"></div><br>
Consider an event loop with 2 queue, ready and waiting. We create a new task/coroutine to perform an IO 
operation or configure remote device and put it in ready queue. Initially execution control is with event
loop which it passes to the new task in ready queue. Task starts execution. Whenever task need to wait 
from results, it can move to waiting queue and give control back to event loop. Event loop then gives the
control to next task in ready queue. Meanwhile when task get the result, it is moved from waiting to ready
queue. 

## 3. Async and await syntax
### 3.1 starting co-routines sequentially 

```python
import asyncio
import time

async def say_after(delay, what):
    await asyncio.sleep(delay)
    print(what)

async def main():                    # refer your function as a coroutine
    print(f"started at {time.strftime('%X')}")

    await say_after(1, 'hello')      # mark your statement which can go for IO bound work
    await say_after(2, 'world')

    print(f"finished at {time.strftime('%X')}")


# Python 3.7+
asyncio.run(main())                  # this gets the event loop and runs the coroutine
```
asyncio.run function runs the passed coroutine, taking care of managing the asyncio event loop.

### 3.2 starting co-routines concurrently 

```python
import asyncio
import time

async def say_after(delay, what):
    await asyncio.sleep(delay)
    print(what)
    
async def main():
    task1 = asyncio.create_task(
        say_after(1, 'hello'))

    task2 = asyncio.create_task(
        say_after(2, 'world'))

    print(f"started at {time.strftime('%X')}")
    await asyncio.gather(task1, task2)   
    print(f"finished at {time.strftime('%X')}")
    
asyncio.run(main())
```
asyncio.gather run the task asynchronously
## 4. Example

Suppose you have to get crawled data for a given URL(called baseurl in code) and the url found in baseurl html code recursively till we reach a depth. Eventually we write content of url in a file. <br>
![Synchronous code](https://github.com/Ankit-rana/tiny-search-engine/blob/master/crawler.py):
```
$ time python3.8 crawler.py http://ankit-rana.github.io/blog/2020/01/11/asyncio ./data/ 3

real	0m29.915s
user	0m6.503s
sys	0m0.185s
```
![Asynchronous code](https://github.com/Ankit-rana/tiny-search-engine/blob/async_version/crawler.py):
```
$ time python3.8 crawler.py http://ankit-rana.github.io/blog/2020/01/11/asyncio ./data/ 3
real	0m7.380s
user	0m6.494s
sys	0m0.179s
```

## 5. Appendix


#### 5.1 [Python Official Doc.](https://docs.python.org/3.7/library/asyncio.html)<br>
#### 5.2 [Michael Kennedy course on Asynchronous programming in Python](https://training.talkpython.fm/courses/explore_async_python/async-in-python-with-threading-and-multiprocessing)
#### 5.3 <a href="https://github.com/Ankit-rana/tiny-search-engine/blob/async_version/crawler.py">Example's Asyncio Code</a>
